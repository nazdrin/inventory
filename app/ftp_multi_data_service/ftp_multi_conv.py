import os
import json
import asyncio
import logging
from io import BytesIO
from datetime import datetime
from ftplib import FTP, error_perm

from dotenv import load_dotenv
from sqlalchemy.future import select
from app.database import get_async_db
from app.models import MappingBranch
from app.services.database_service import process_database_service

# =========================
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# =========================
ENTERPRISE_CODE = "2"
FILE_TYPE = "both"
DEFAULT_VAT = 20.0
TEMP_DIR = "./temp"

load_dotenv()

FTP_HOST = os.getenv("FTP_HOST", "127.0.0.1")
FTP_PORT = int(os.getenv("FTP_PORT", "21"))
FTP_USER = os.getenv("FTP_USER", "zoomagazin")
FTP_PASS = os.getenv("FTP_PASS", "")
FTP_DIR = os.getenv("FTP_DIR", "/")

logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")


# =========================
# –£—Ç–∏–ª–∏—Ç—ã FTP
# =========================
def _join_ftp(*parts: str) -> str:
    cleaned = [p.strip("/") for p in parts if p and p != "/"]
    return "/" + "/".join(cleaned) if cleaned else "/"


def _list_json_files_with_mtime(ftp, path):
    ftp.encoding = 'latin1'
    try:
        names = ftp.nlst(path)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {e}")
        return []

    json_files = []
    for name in names:
        if name.lower().endswith(".json"):
            try:
                mdtm = ftp.sendcmd(f"MDTM {name}")
                dt_str = mdtm.replace("213 ", "")
                mtime = datetime.strptime(dt_str, "%Y%m%d%H%M%S")
                json_files.append((name, mtime))
            except Exception:
                continue

    return sorted(json_files, key=lambda x: x[1], reverse=True)


def _download_to_string(ftp, path, filename):
    buf = BytesIO()
    ftp.retrbinary(f"RETR {filename}", buf.write)
    buf.seek(0)
    try:
        return buf.read().decode("utf-8")
    except UnicodeDecodeError:
        buf.seek(0)
        return buf.read().decode("windows-1251")


# =========================
# –î–æ—Å—Ç—É–ø –∫ –ë–î
# =========================
async def fetch_store_branches(enterprise_code: str) -> list[dict]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ [{'store_id': 'Zoomagazin_1.json', 'branch': '111'}, ...]"""
    async with get_async_db() as session:
        result = await session.execute(
            select(MappingBranch.store_id, MappingBranch.branch)
            .where(MappingBranch.enterprise_code == enterprise_code)
        )
        rows = result.all()
        if not rows:
            raise ValueError(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö mapping_branch –¥–ª—è enterprise_code={enterprise_code}")
        return [{"store_id": r[0], "branch": str(r[1])} for r in rows]


# =========================
# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
# =========================
def _normalize_input(json_str: str) -> list[dict]:
    data = json.loads(json_str)
    if isinstance(data, dict):
        return [data]
    if isinstance(data, list):
        return data
    raise ValueError("–û–∂–∏–¥–∞–ª—Å—è JSON-–æ–±—ä–µ–∫—Ç –∏–ª–∏ –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤")


def transform_catalog(items: list[dict]) -> list[dict]:
    return [{
        "code": str(it.get("Id", "")),
        "name": str(it.get("Name", "") or ""),
        "producer": "",
        "barcode": str(it.get("Barcode", "") or ""),
        "vat": DEFAULT_VAT,
    } for it in items]


def transform_stock(items: list[dict], branch: str) -> list[dict]:
    out = []
    for it in items:
        price = max(float(it.get("MaxPrice", 0.0) or 0.0), 0.0)
        qty = max(float(it.get("TotalStock", 0.0) or 0.0), 0.0)
        out.append({
            "branch": branch,
            "code": str(it.get("Id", "")),
            "price": price,
            "qty": qty,
            "price_reserve": price
        })
    return out


def save_to_json(data, enterprise_code: str, file_type: str) -> str:
    out_dir = os.path.join(TEMP_DIR, str(enterprise_code))
    os.makedirs(out_dir, exist_ok=True)
    path = os.path.join(out_dir, f"{file_type}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    logging.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {path}")
    return path


async def send_catalog_data(data: list[dict], enterprise_code: str):
    path = save_to_json(data, enterprise_code, "catalog")
    await process_database_service(path, "catalog", enterprise_code)


async def send_stock_data(data: list[dict], enterprise_code: str):
    path = save_to_json(data, enterprise_code, "stock")
    await process_database_service(path, "stock", enterprise_code)


# =========================
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞
# =========================
async def process_catalog(ftp: FTP, enterprise_code: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ ‚Äî –∏—â–µ—Ç —Ñ–∞–π–ª catalog-Zoomagazin_2sm.json"""
    incoming_abs = FTP_DIR if FTP_DIR.startswith("/") else _join_ftp("/", FTP_DIR)
    files = _list_json_files_with_mtime(ftp, incoming_abs)
    target_file = None

    for name, _ in files:
        if name.lower() == "catalog-zoomagazin_2sm.json":
            target_file = name
            break

    if not target_file:
        logging.warning("–§–∞–π–ª catalog-Zoomagazin_2sm.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return

    logging.info(f"üìò –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞: {target_file}")
    raw = _download_to_string(ftp, incoming_abs, target_file)
    items = _normalize_input(raw)
    catalog = transform_catalog(items)
    await send_catalog_data(catalog, enterprise_code)


# =========================
# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–æ–∫–∞
# =========================
async def process_stock(ftp: FTP, enterprise_code: str):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Å—Ç–æ–∫–∏ –ø–æ store_id –∏–∑ mapping_branch"""
    incoming_abs = FTP_DIR if FTP_DIR.startswith("/") else _join_ftp("/", FTP_DIR)
    store_branches = await fetch_store_branches(enterprise_code)
    all_stock = []

    files = _list_json_files_with_mtime(ftp, incoming_abs)
    file_names = [name for name, _ in files]

    for sb in store_branches:
        store_id = sb["store_id"]
        branch = sb["branch"]

        # –∏—â–µ–º —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º
        match = next((f for f in file_names if f == store_id), None)
        if not match:
            logging.warning(f"‚ùó –§–∞–π–ª {store_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ FTP, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue

        logging.info(f"üíæ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–æ–∫–∞: {store_id} ‚Üí branch {branch}")
        raw = _download_to_string(ftp, incoming_abs, match)
        items = _normalize_input(raw)
        stock = transform_stock(items, branch)
        all_stock.extend(stock)

    if not all_stock:
        logging.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å—Ç–æ–∫–∞.")
        return

    await send_stock_data(all_stock, enterprise_code)


# =========================
# –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π
# =========================
async def run_service(enterprise_code: str, file_type: str):
    ftp = FTP()
    ftp.connect(FTP_HOST, FTP_PORT, timeout=30)
    ftp.login(FTP_USER, FTP_PASS)
    ftp.encoding = "utf-8"

    try:
        if file_type in ("catalog", "both"):
            await process_catalog(ftp, enterprise_code)

        if file_type in ("stock", "both"):
            await process_stock(ftp, enterprise_code)

    except Exception as e:
        logging.exception(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        try:
            ftp.quit()
        except Exception:
            pass


# –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫
if __name__ == "__main__":
    asyncio.run(run_service(ENTERPRISE_CODE, FILE_TYPE))
