import os
import json
import asyncio
import logging
from io import BytesIO
from datetime import datetime, timedelta
from ftplib import FTP, error_perm

from dotenv import load_dotenv
from sqlalchemy.future import select

from app.database import get_async_db, EnterpriseSettings  # EnterpriseSettings –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é, –Ω–æ –ø—É—Å—Ç—å –±—É–¥–µ—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
from app.models import MappingBranch
from app.services.database_service import process_database_service

# =========================
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# =========================
load_dotenv()

FTP_HOST = os.getenv("FTP_HOST", "127.0.0.1")
FTP_PORT = int(os.getenv("FTP_PORT", "21"))
FTP_USER = os.getenv("FTP_USER", "zoomagazin")
FTP_PASS = os.getenv("FTP_PASS", "")

FTP_DIR = os.getenv("FTP_DIR", "/upload")
FTP_ARCHIVE_DIR = os.getenv("FTP_ARCHIVE_DIR", "/archive")
FTP_FAILED_DIR = os.getenv("FTP_FAILED_DIR", "/failed")

FTP_KEEP_LATEST = int(os.getenv("FTP_KEEP_LATEST", "3"))
FTP_MAX_AGE_DAYS = int(os.getenv("FTP_MAX_AGE_DAYS", "7"))

TEMP_FILE_PATH = os.getenv("TEMP_FILE_PATH", "./temp")
ENTERPRISE_CODE = os.getenv("ENTERPRISE_CODE", "2")  # –£–∫–∞–∂–∏ —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–¥ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è
FILE_TYPE = os.getenv("FILE_TYPE", "both").lower()    # 'catalog' | 'stock' | 'both'

DEFAULT_VAT = float(os.getenv("DEFAULT_VAT", "20.0"))

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

# =========================
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# =========================

def _ensure_remote_dir(ftp: FTP, path: str) -> None:
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–æ–∑–¥–∞—ë—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –Ω–∞ FTP, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç."""
    if not path or path == "/":
        return
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –∏–¥—ë–º –≥–ª—É–±–∂–µ
    parts = [p for p in path.strip("/").split("/") if p]
    cur = ""
    for p in parts:
        cur += f"/{p}"
        try:
            ftp.mkd(cur)
        except error_perm as e:
            # –µ—Å–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –Ω–æ—Ä–º–∞–ª—å–Ω–æ
            if not str(e).startswith("550"):
                raise

def connect_ftp(cwd: str = FTP_DIR) -> FTP:
    ftp = FTP()
    ftp.connect(FTP_HOST, FTP_PORT, timeout=30)
    ftp.login(FTP_USER, FTP_PASS)
    # –≤–∞–∂–Ω–æ–µ ‚Äî UTF-8 –¥–ª—è –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤
    ftp.encoding = "utf-8"
    # –∑–∞—Å—Ç—Ä–∞—Ö—É–µ–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    for d in (FTP_DIR, FTP_ARCHIVE_DIR, FTP_FAILED_DIR):
        _ensure_remote_dir(ftp, d)
    ftp.cwd(cwd)
    logging.info(f"FTP connected. CWD: {cwd}")
    return ftp

def _list_json_files_with_mtime(ftp: FTP):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (name, mtime: datetime) –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ, —Ç–æ–ª—å–∫–æ *.json."""
    files = []
    try:
        # –ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ MLSD (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç modify=YYYYMMDDHHMMSS)
        for name, facts in ftp.mlsd():
            if facts.get("type") == "file" and name.lower().endswith(".json"):
                m = facts.get("modify")
                if m:
                    mt = datetime.strptime(m, "%Y%m%d%H%M%S")
                else:
                    # –∑–∞–ø–∞—Å–Ω–æ–π –ø—É—Ç—å ‚Äî MDTM
                    try:
                        mt_raw = ftp.sendcmd(f"MDTM {name}")[4:].strip()
                        mt = datetime.strptime(mt_raw, "%Y%m%d%H%M%S")
                    except Exception:
                        mt = datetime.min
                files.append((name, mt))
    except (error_perm, AttributeError):
        # –ï—Å–ª–∏ MLSD –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω ‚Äî –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        names = [n for n in ftp.nlst() if n.lower().endswith(".json")]
        for n in names:
            try:
                mt_raw = ftp.sendcmd(f"MDTM {n}")[4:].strip()
                mt = datetime.strptime(mt_raw, "%Y%m%d%H%M%S")
            except Exception:
                mt = datetime.min
            files.append((n, mt))
    return files

def _download_to_string(ftp: FTP, filename: str) -> str:
    buf = BytesIO()
    ftp.retrbinary(f"RETR {filename}", buf.write)
    buf.seek(0)
    return buf.read().decode("utf-8")

def _move_remote(ftp: FTP, src_name: str, dst_dir: str) -> str:
    """–ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É (archive/failed) —Å –¥–∞—Ç–æ–π –≤ –∏–º–µ–Ω–∏."""
    _ensure_remote_dir(ftp, dst_dir)
    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
    # –¥–æ–±–∞–≤–∏–º timestamp –ø–µ—Ä–µ–¥ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
    base, ext = os.path.splitext(os.path.basename(src_name))
    dst_name = f"{base}__{ts}{ext or ''}"
    src_path = f"{FTP_DIR.rstrip('/')}/{src_name}"
    dst_path = f"{dst_dir.rstrip('/')}/{dst_name}"
    ftp.rename(src_path, dst_path)
    return dst_path

def _cleanup_incoming(ftp: FTP, keep_latest: int, max_age_days: int):
    """–û—Å—Ç–∞–≤–ª—è–µ–º N –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤, –æ—Å—Ç–∞–ª—å–Ω–æ–µ —Å—Ç–∞—Ä—à–µ max_age_days ‚Äî —É–¥–∞–ª—è–µ–º."""
    now = datetime.now()
    files = _list_json_files_with_mtime(ftp)
    if not files:
        return
    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —É–±—ã–≤.
    files.sort(key=lambda x: x[1], reverse=True)
    latest_set = set(name for name, _ in files[:max(0, keep_latest)])
    for name, mtime in files:
        if name in latest_set:
            continue
        if (now - mtime).days >= max_age_days:
            try:
                ftp.delete(name)
                logging.info(f"üßπ –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {name}")
            except Exception as e:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {name}: {e}")

# =========================
# –î–æ—Å—Ç—É–ø –∫ –ë–î
# =========================

async def fetch_branch_by_enterprise_code(enterprise_code: str) -> str:
    async with get_async_db() as session:
        result = await session.execute(
            select(MappingBranch.branch).where(MappingBranch.enterprise_code == enterprise_code)
        )
        branch = result.scalars().first()
        if not branch:
            raise ValueError(f"Branch –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è enterprise_code={enterprise_code}")
        return str(branch)

# =========================
# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
# =========================

def _normalize_input(json_content: str) -> list[dict]:
    data = json.loads(json_content)
    if isinstance(data, dict):
        data = [data]
    elif not isinstance(data, list):
        raise ValueError("–û–∂–∏–¥–∞–ª—Å—è JSON-–æ–±—ä–µ–∫—Ç –∏–ª–∏ –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤")
    return data

def transform_catalog(items: list[dict]) -> list[dict]:
    out = []
    for it in items:
        out.append({
            "code": str(it.get("Id", "")),
            "name": str(it.get("Name", "") or ""),
            "producer": "",
            "barcode": str(it.get("Barcode", "") or ""),
            "vat": DEFAULT_VAT,
        })
    return out

def transform_stock(items: list[dict], branch: str) -> list[dict]:
    out = []
    for it in items:
        price = float(it.get("MaxPrice", 0.0) or 0.0)
        stock = float(it.get("TotalStock", 0.0) or 0.0)
        # –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö
        price = max(price, 0.0)
        stock = max(stock, 0.0)
        out.append({
            "branch": branch,
            "code": str(it.get("Id", "")),
            "price": price,
            "qty": stock,
            "price_reserve": price
        })
    return out

def save_to_json(data, enterprise_code: str, file_type: str) -> str:
    dir_path = os.path.join(TEMP_FILE_PATH, str(enterprise_code))
    os.makedirs(dir_path, exist_ok=True)
    file_path = os.path.join(dir_path, f"{file_type}.json")
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    logging.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {file_path}")
    return file_path

async def send_catalog_data(file_path: str, enterprise_code: str):
    await process_database_service(file_path, "catalog", enterprise_code)

async def send_stock_data(file_path: str, enterprise_code: str):
    await process_database_service(file_path, "stock", enterprise_code)

# =========================
# –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π
# =========================

async def run_service(enterprise_code: str, file_type: str = FILE_TYPE):
    """
    file_type: 'catalog' | 'stock' | 'both'
    """
    ftp = None
    latest_name = None
    try:
        ftp = connect_ftp(FTP_DIR)
        files = _list_json_files_with_mtime(ftp)
        if not files:
            logging.info("–ù–µ—Ç JSON-—Ñ–∞–π–ª–æ–≤ –≤–æ –≤—Ö–æ–¥—è—â–µ–π –ø–∞–ø–∫–µ.")
            return

        # –±–µ—Ä—ë–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π
        files.sort(key=lambda x: x[1], reverse=True)
        latest_name, latest_mtime = files[0]
        logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {latest_name} (mtime={latest_mtime})")

        # –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        json_str = _download_to_string(ftp, latest_name)
        items = _normalize_input(json_str)

        # —á—Ç–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å
        ft = (file_type or "both").lower()
        if ft not in ("catalog", "stock", "both"):
            raise ValueError("file_type –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'catalog', 'stock' –∏–ª–∏ 'both'")

        if ft in ("catalog", "both"):
            catalog = transform_catalog(items)
            cat_path = save_to_json(catalog, enterprise_code, "catalog")
            await send_catalog_data(cat_path, enterprise_code)

        if ft in ("stock", "both"):
            branch = await fetch_branch_by_enterprise_code(enterprise_code)
            stock = transform_stock(items, branch)
            st_path = save_to_json(stock, enterprise_code, "stock")
            await send_stock_data(st_path, enterprise_code)

        # –≤ –∞—Ä—Ö–∏–≤
        archived = _move_remote(ftp, latest_name, FTP_ARCHIVE_DIR)
        logging.info(f"üì¶ –ü–µ—Ä–µ–º–µ—â—ë–Ω –≤ –∞—Ä—Ö–∏–≤: {archived}")

        # —É–±–æ—Ä–∫–∞
        _cleanup_incoming(ftp, FTP_KEEP_LATEST, FTP_MAX_AGE_DAYS)

    except Exception as e:
        logging.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {latest_name or ''}: {e}")
        try:
            if ftp and latest_name:
                failed = _move_remote(ftp, latest_name, FTP_FAILED_DIR)
                logging.warning(f"–§–∞–π–ª –ø–µ—Ä–µ–º–µ—â—ë–Ω –≤ failed: {failed}")
        except Exception as e2:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ failed: {e2}")
        # –º–æ–∂–Ω–æ –Ω–µ –ø–∞–¥–∞—Ç—å –¥–∞–ª—å—à–µ, –µ—Å–ª–∏ —ç—Ç–æ —Å–µ—Ä–≤–∏—Å-–∫—Ä–æ–Ω
    finally:
        try:
            if ftp:
                ftp.quit()
        except Exception:
            pass

# =========================
# –ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ
# =========================

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä: –¥–ª—è zoomagazin —É–∫–∞–∂–∏ ENTERPRISE_CODE –≤ .env
    # FILE_TYPE –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å 'both', –∏–ª–∏ –∑–∞–¥–∞—Ç—å 'catalog'/'stock'
    asyncio.run(run_service(ENTERPRISE_CODE, FILE_TYPE))
