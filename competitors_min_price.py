import io
import json
import os
from pathlib import Path
from typing import Optional, List, Dict, Any

import pandas as pd

# Google Drive
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload


# === –ù–ê–°–¢–†–û–ô–ö–ò –ö–û–õ–û–ù–û–ö (–∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ) ===
CODE_COL = "–ö–æ–¥ —Ç–æ–≤–∞—Ä–∞ Tabletki.ua"
PRICE_RETAIL_COL = "–¶–µ–Ω–∞ —Ä–æ–∑–Ω."
FALLBACK_PRICE_COL = "–¶–µ–Ω–∞"  # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ "–¶–µ–Ω–∞ —Ä–æ–∑–Ω." –Ω–µ—Ç


# === ENV –ù–ê–°–¢–†–û–ô–ö–ò ===
# –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å —Å—Ç–∞—Ä—ã–π ROOT_DIR —Ö–∞—Ä–¥–∫–æ–¥–æ–º, –Ω–æ –ª—É—á—à–µ —á–µ—Ä–µ–∑ env
ROOT_DIR = Path(os.getenv("COMPETITORS_ROOT_DIR", "/Users/dmitrijnazdrin/Documents/Competitors"))

# –°–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤ –¥–ª—è —Ä–∞—Å–∫–ª–∞–¥–∫–∏ Total (—Ñ–æ—Ä–º–∞—Ç env: COMPETITOR_CITIES=Kyiv,Lviv,Odessa)
COMPETITOR_CITIES = [c.strip() for c in os.getenv("COMPETITOR_CITIES", "").split(",") if c.strip()]

# Google Drive folder id
COMPETITOR_GDRIVE_FOLDER_ID = os.getenv("COMPETITOR_GDRIVE_FOLDER_ID", "").strip()

# Service account credentials path
GOOGLE_DRIVE_CREDENTIALS_PATH = os.getenv("GOOGLE_DRIVE_CREDENTIALS_PATH", "").strip()

# –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –Ω–∞ Google Drive
TOTAL_FILENAME = os.getenv("COMPETITOR_TOTAL_FILENAME", "competitors_delivery_total.json").strip()
CITY_FILENAME_TEMPLATE = os.getenv("COMPETITOR_CITY_FILENAME_TEMPLATE", "competitors_delivery_{city}.json").strip()


def _is_valid_drive_folder_id(folder_id: str) -> bool:
    """Basic sanity-check for Google Drive folder id (avoid placeholders/typos)."""
    if not folder_id:
        return False
    # common placeholder patterns
    low = folder_id.lower()
    if "—Ç–≤–æ–π" in low or "your" in low or "id_" in low:
        return False
    # must not contain spaces or quotes
    if any(ch.isspace() for ch in folder_id) or "'" in folder_id or '"' in folder_id:
        return False
    # Google IDs are typically URL-safe base64-like (letters/digits/_-)
    allowed = set("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_-" )
    if any(ch not in allowed for ch in folder_id):
        return False
    # minimal length
    return len(folder_id) >= 10


def _normalize_code_series(s: pd.Series) -> pd.Series:
    """–ü—Ä–∏–≤–æ–¥–∏–º –∫–æ–¥—É –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –≤–∏–¥—É –±–µ–∑ .0 –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤."""
    # –°–Ω–∞—á–∞–ª–∞ –≤ numeric, —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å .0, –ø–æ—Ç–æ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ Int/str
    # –ù–æ —á–∞—Å—Ç—å –∫–æ–¥–æ–≤ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π ‚Äî –¥–µ–ª–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ.
    def norm_one(v: Any) -> Optional[str]:
        if pd.isna(v):
            return None
        if isinstance(v, (int,)):
            return str(v)
        if isinstance(v, float):
            # 1080612.0 -> 1080612
            if v.is_integer():
                return str(int(v))
            return str(v)
        # string
        t = str(v).strip()
        if t.endswith(".0"):
            t = t[:-2]
        return t

    return s.map(norm_one)


def _normalize_price_series(s: pd.Series) -> pd.Series:
    """–ü—Ä–∏–≤–æ–¥–∏–º —Ü–µ–Ω—É –∫ float, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º '123,45'."""
    # –ø—Ä–∏–≤–æ–¥–∏–º –∫ str, –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É, –∑–∞—Ç–µ–º to_numeric
    s2 = s.astype(str).str.replace(" ", "", regex=False).str.replace(",", ".", regex=False)
    return pd.to_numeric(s2, errors="coerce")


def read_excels_min_price(folder: Path) -> pd.DataFrame:
    """–ß–∏—Ç–∞–µ—Ç –≤—Å–µ xlsx –≤ –ø–∞–ø–∫–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame [code, price] c min price –ø–æ code."""
    excel_files = list(folder.glob("*.xlsx"))
    if not excel_files:
        return pd.DataFrame(columns=["code", "price"])

    frames: List[pd.DataFrame] = []

    for file_path in excel_files:
        print(f"  - —á–∏—Ç–∞—é —Ñ–∞–π–ª: {file_path.name}")
        try:
            df = pd.read_excel(file_path)
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path.name}: {e}")
            continue

        if CODE_COL not in df.columns:
            print(f"    ‚ö† –ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '{CODE_COL}', —Ñ–∞–π–ª –ø—Ä–æ–ø—É—Å–∫–∞—é.")
            continue

        if PRICE_RETAIL_COL in df.columns:
            price_col = PRICE_RETAIL_COL
        elif FALLBACK_PRICE_COL in df.columns:
            price_col = FALLBACK_PRICE_COL
        else:
            print(
                f"    ‚ö† –ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ '{PRICE_RETAIL_COL}' –∏–ª–∏ '{FALLBACK_PRICE_COL}', —Ñ–∞–π–ª –ø—Ä–æ–ø—É—Å–∫–∞—é."
            )
            continue

        tmp = df[[CODE_COL, price_col]].copy()
        tmp.rename(columns={CODE_COL: "code", price_col: "price"}, inplace=True)

        tmp["code"] = _normalize_code_series(tmp["code"])
        tmp["price"] = _normalize_price_series(tmp["price"])

        tmp = tmp.dropna(subset=["code", "price"])

        frames.append(tmp)

    if not frames:
        return pd.DataFrame(columns=["code", "price"])

    all_data = pd.concat(frames, ignore_index=True)

    # min price by code
    result = all_data.groupby("code", as_index=False)["price"].min()
    return result


def delete_local_excels(folder: Path) -> None:
    excel_files = list(folder.glob("*.xlsx"))
    for file_path in excel_files:
        try:
            file_path.unlink()
            print(f"  üóë –£–¥–∞–ª—ë–Ω —Ñ–∞–π–ª: {file_path.name}")
        except Exception as e:
            print(f"  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {file_path.name}: {e}")


def build_drive_service(credentials_path: str):
    scopes = ["https://www.googleapis.com/auth/drive"]
    creds = service_account.Credentials.from_service_account_file(credentials_path, scopes=scopes)
    return build("drive", "v3", credentials=creds)


def gdrive_find_files_by_name(service, folder_id: str, filename: str) -> List[Dict[str, str]]:
    q = f"'{folder_id}' in parents and name = '{filename}' and trashed = false"
    resp = service.files().list(q=q, fields="files(id,name)", pageSize=100).execute()
    return resp.get("files", [])


def gdrive_delete_file(service, file_id: str) -> None:
    service.files().delete(fileId=file_id).execute()


def gdrive_download_json(service, file_id: str) -> List[Dict[str, Any]]:
    request = service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        _, done = downloader.next_chunk()
    fh.seek(0)
    raw = fh.read().decode("utf-8")
    try:
        data = json.loads(raw)
        if isinstance(data, list):
            return data
        return []
    except Exception:
        return []


def gdrive_create_json(service, folder_id: str, filename: str, rows: List[Dict[str, Any]]) -> str:
    payload = json.dumps(rows, ensure_ascii=False)
    media = MediaIoBaseUpload(io.BytesIO(payload.encode("utf-8")), mimetype="application/json", resumable=False)
    metadata = {"name": filename, "parents": [folder_id]}
    created = service.files().create(body=metadata, media_body=media, fields="id").execute()
    return created["id"]


def gdrive_update_json(service, file_id: str, rows: List[Dict[str, Any]]) -> None:
    payload = json.dumps(rows, ensure_ascii=False)
    media = MediaIoBaseUpload(io.BytesIO(payload.encode("utf-8")), mimetype="application/json", resumable=False)
    service.files().update(fileId=file_id, media_body=media).execute()


def gdrive_upsert_total_by_city(
    service,
    folder_id: str,
    total_filename: str,
    city: str,
    incoming_rows: List[Dict[str, Any]],
) -> None:
    """Create TOTAL file if missing; otherwise update only rows for the given city inside TOTAL."""
    existing_files = gdrive_find_files_by_name(service, folder_id, total_filename)

    if not existing_files:
        # –ï—Å–ª–∏ TOTAL –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω ‚Äî —Å–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ —Å –¥–∞–Ω–Ω—ã–º –≥–æ—Ä–æ–¥–æ–º
        new_id = gdrive_create_json(service, folder_id, total_filename, incoming_rows)
        print(f"  ‚úÖ Total JSON —Å–æ–∑–¥–∞–Ω (–Ω–µ –±—ã–ª–æ —Ñ–∞–π–ª–∞) –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è –≥–æ—Ä–æ–¥–∞ {city}: {total_filename} ({new_id})")
        return

    file_id = existing_files[0]["id"]
    existing_rows = gdrive_download_json(service, file_id)
    merged = merge_city_rows(existing_rows, incoming_rows, city)
    gdrive_update_json(service, file_id, merged)
    print(f"  ‚úÖ Total JSON –æ–±–Ω–æ–≤–ª—ë–Ω –ø–æ –≥–æ—Ä–æ–¥—É {city}: {total_filename} ({file_id})")


def expand_total_to_cities(min_prices_df: pd.DataFrame, cities: List[str]) -> List[Dict[str, Any]]:
    rows: List[Dict[str, Any]] = []
    for _, r in min_prices_df.iterrows():
        code = str(r["code"])  # —É–∂–µ —Å—Ç—Ä–æ–∫–∞
        price = float(r["price"])  # float
        for city in cities:
            rows.append({"code": code, "city": city, "delivery_price": price})
    return rows


def city_rows_from_df(min_prices_df: pd.DataFrame, city: str) -> List[Dict[str, Any]]:
    rows: List[Dict[str, Any]] = []
    for _, r in min_prices_df.iterrows():
        rows.append({"code": str(r["code"]), "city": city, "delivery_price": float(r["price"])})
    return rows


def merge_city_rows(existing: List[Dict[str, Any]], incoming: List[Dict[str, Any]], city: str) -> List[Dict[str, Any]]:
    """–û–±–Ω–æ–≤–ª—è–µ–º/–¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞ (–∫–ª—é—á: code+city)."""
    # –ò–Ω–¥–µ–∫—Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö
    index: Dict[tuple, Dict[str, Any]] = {}
    kept: List[Dict[str, Any]] = []

    for row in existing:
        try:
            c = str(row.get("code", "")).strip()
            ct = str(row.get("city", "")).strip()
            if not c or not ct:
                continue
            key = (c, ct)
            index[key] = {"code": c, "city": ct, "delivery_price": float(row.get("delivery_price"))}
        except Exception:
            continue

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Ö–æ–¥—è—â–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    for row in incoming:
        c = str(row.get("code", "")).strip()
        ct = str(row.get("city", "")).strip()
        if not c or not ct:
            continue
        if ct != city:
            continue
        try:
            p = float(row.get("delivery_price"))
        except Exception:
            continue
        index[(c, ct)] = {"code": c, "city": ct, "delivery_price": p}

    # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ —Å–ø–∏—Å–æ–∫
    for _, v in index.items():
        kept.append(v)

    # –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    kept.sort(key=lambda x: (x["city"], x["code"]))
    return kept


def process_total(service) -> None:
    total_dir = ROOT_DIR / "Total"
    if not total_dir.exists() or not total_dir.is_dir():
        print("‚ñ∂ –ü–∞–ø–∫–∞ Total –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é Total")
        return

    print("\n‚ñ∂ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏: Total")

    if not COMPETITOR_CITIES:
        print("  ‚ö† COMPETITOR_CITIES –ø—É—Å—Ç–æ–π. Total –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–ª—å–∑—è (–Ω—É–∂–Ω–æ —Å–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤ –¥–ª—è —Ä–∞—Å–∫–ª–∞–¥–∫–∏).")
        return

    min_df = read_excels_min_price(total_dir)
    if min_df.empty:
        print("  ‚ö† –í Total –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö (xlsx –ø—É—Å—Ç—ã–µ/–Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω—ã) ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é.")
        # –≤—Å—ë —Ä–∞–≤–Ω–æ —á–∏—Å—Ç–∏–º xlsx
        delete_local_excels(total_dir)
        return

    rows = expand_total_to_cities(min_df, COMPETITOR_CITIES)

    # –ù–∞ Total: —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –≤ GDrive –ø–∞–ø–∫–µ –∏ –≥—Ä—É–∑–∏–º –Ω–æ–≤—ã–π
    if not COMPETITOR_GDRIVE_FOLDER_ID:
        print("  ‚ùå –ù–µ –∑–∞–¥–∞–Ω COMPETITOR_GDRIVE_FOLDER_ID ‚Äî –Ω–µ –º–æ–≥—É –∑–∞–≥—Ä—É–∑–∏—Ç—å Total JSON.")
    else:
        existing_files = gdrive_find_files_by_name(service, COMPETITOR_GDRIVE_FOLDER_ID, TOTAL_FILENAME)
        for f in existing_files:
            try:
                gdrive_delete_file(service, f["id"])
                print(f"  üóë –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –Ω–∞ Google Drive: {f['name']} ({f['id']})")
            except Exception as e:
                print(f"  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {f['name']} ({f['id']}): {e}")

        try:
            new_id = gdrive_create_json(service, COMPETITOR_GDRIVE_FOLDER_ID, TOTAL_FILENAME, rows)
            print(f"  ‚úÖ Total JSON –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ Google Drive: {TOTAL_FILENAME} ({new_id})")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Total JSON –Ω–∞ Google Drive: {e}")

    # –£–¥–∞–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ excel
    delete_local_excels(total_dir)


def process_city_folder(service, city_dir: Path) -> None:
    city = city_dir.name
    print(f"\n‚ñ∂ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏: {city}")

    min_df = read_excels_min_price(city_dir)
    if min_df.empty:
        print("  ‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–æ—Ä–æ–¥–∞ (xlsx –ø—É—Å—Ç—ã–µ/–Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω—ã) ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é.")
        delete_local_excels(city_dir)
        return

    incoming_rows = city_rows_from_df(min_df, city)

    if not _is_valid_drive_folder_id(COMPETITOR_GDRIVE_FOLDER_ID):
        print(
            "  ‚ùå COMPETITOR_GDRIVE_FOLDER_ID –Ω–µ –∑–∞–¥–∞–Ω –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω. "
            "–£–∫–∞–∂–∏ —Ä–µ–∞–ª—å–Ω—ã–π ID –ø–∞–ø–∫–∏ Google Drive (—Å—Ç—Ä–æ–∫–∞ –∏–∑ URL –ø–∞–ø–∫–∏)."
        )
        delete_local_excels(city_dir)
        return

    # –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ: –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–ø–æ–∫ –≥–æ—Ä–æ–¥–æ–≤ –¥–æ–ª–∂–Ω—ã –¥–æ–ø–æ–ª–Ω—è—Ç—å/–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å TOTAL-—Ñ–∞–π–ª
    try:
        gdrive_upsert_total_by_city(
            service,
            COMPETITOR_GDRIVE_FOLDER_ID,
            TOTAL_FILENAME,
            city,
            incoming_rows,
        )
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è TOTAL JSON –ø–æ –≥–æ—Ä–æ–¥—É {city}: {e}")

    # –£–¥–∞–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ excel
    delete_local_excels(city_dir)


def main():
    if not ROOT_DIR.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {ROOT_DIR}")
        return

    if not GOOGLE_DRIVE_CREDENTIALS_PATH:
        print("‚ùå –ù–µ –∑–∞–¥–∞–Ω GOOGLE_DRIVE_CREDENTIALS_PATH (–ø—É—Ç—å –∫ service account json)")
        return

    service = build_drive_service(GOOGLE_DRIVE_CREDENTIALS_PATH)

    # 1) Total
    process_total(service)

    # 2) –ì–æ—Ä–æ–¥–∞ (–≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏ –∫—Ä–æ–º–µ Total)
    for item in ROOT_DIR.iterdir():
        if not item.is_dir():
            continue
        if item.name == "Total":
            continue

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å xlsx
        if list(item.glob("*.xlsx")):
            process_city_folder(service, item)


if __name__ == "__main__":
    main()